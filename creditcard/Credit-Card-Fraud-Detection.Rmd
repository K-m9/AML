---
title: "Credit Card Fraud Detection"
output:
  html_document:
    df_print: paged
---

This is an Kaggle project, link is: https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/data?select=creditcard.csv


## Set up
```{r}
# Libraries
library(pROC, quietly=TRUE)
library(microbenchmark, quietly=TRUE)

# Set seed so the train/test split is reproducible
set.seed(42)

# Read in the data and split it into train/test subsets
credit.card.data = read.csv("creditcard.csv")

train.test.split <- sample(2
	, nrow(credit.card.data)
	, replace = TRUE
	, prob = c(0.7, 0.3))
train = credit.card.data[train.test.split == 1,]
test = credit.card.data[train.test.split == 2,]
```

## Data Description
The data shows no NULL values, and the class is pretty imbalanced.
```{r}
summary(credit.card.data)
max(colSums(is.na(credit.card.data)))
```
```{r}
library(ggplot2)

# 生成柱状图
ggplot(credit.card.data, aes(x = factor(Class))) +  # 将Class转换为因子
  geom_bar(aes(fill = factor(Class)),  # 按类别填充颜色
       width = 0.6,                    # 柱子宽度
       show.legend = FALSE) +          # 隐藏图例
  
  # 设置颜色方案
  scale_fill_manual(values = c("#0101DF", "#DF0101")) +
  
  # 添加标题和标签
  labs(title = "Class Distributions \n (0: No Fraud || 1: Fraud)",
       x = "Class",
       y = "Count") +
  
  # 调整标题格式
  theme(
    plot.title = element_text(size = 14, 
                            face = "bold",
                            hjust = 0.5),  # 标题居中
    axis.title = element_text(size = 12)
  )
```


## GBM
```{r}
library(gbm, quietly=TRUE)

# Get the time to train the GBM model
system.time(
	gbm.model <- gbm(Class ~ .
		, distribution = "bernoulli"
		, data = rbind(train, test)
		, n.trees = 500
		, interaction.depth = 3
		, n.minobsinnode = 100
		, shrinkage = 0.01
		, bag.fraction = 0.5
		, train.fraction = nrow(train) / (nrow(train) + nrow(test))
		)
)
# Determine best iteration based on test data
best.iter = gbm.perf(gbm.model, method = "test")

# Get feature importance
gbm.feature.imp = summary(gbm.model, n.trees = best.iter)

# Plot and calculate AUC on test data
gbm.test = predict(gbm.model, newdata = test, n.trees = best.iter)
auc.gbm = roc(test$Class, gbm.test, plot = TRUE, col = "red")
print(auc.gbm)
```
## XGBoost
```{r}
library(xgboost, quietly=TRUE)
xgb.data.train <- xgb.DMatrix(as.matrix(train[, colnames(train) != "Class"]), label = train$Class)
xgb.data.test <- xgb.DMatrix(as.matrix(test[, colnames(test) != "Class"]), label = test$Class)

# Get the time to train the xgboost model
xgb.bench.speed = microbenchmark(
	xgb.model.speed <- xgb.train(data = xgb.data.train
		, params = list(objective = "binary:logistic"
			, eta = 0.1
			, max.depth = 3
			, min_child_weight = 100
			, subsample = 1
			, colsample_bytree = 1
			, nthread = 3
			, eval_metric = "auc"
			)
		, watchlist = list(test = xgb.data.test)
		, nrounds = 500
		, early_stopping_rounds = 40
		, print_every_n = 20
		)
    , times = 5L
)
print(xgb.bench.speed)
print(xgb.model.speed$bestScore)

# Make predictions on test set for ROC curve
xgb.test.speed = predict(xgb.model.speed
                   , newdata = as.matrix(test[, colnames(test) != "Class"])
                   , ntreelimit = xgb.model.speed$best_ntreelimit)
auc.xgb.speed = roc(test$Class, xgb.test.speed, plot = TRUE, col = "blue")
print(auc.xgb.speed)
```

```{r}
# Train a deeper xgboost model to compare accuarcy.
xgb.bench.acc = microbenchmark(
	xgb.model.acc <- xgb.train(data = xgb.data.train
		, params = list(objective = "binary:logistic"
			, eta = 0.1
			, max.depth = 7
			, min_child_weight = 100
			, subsample = 1
			, colsample_bytree = 1
			, nthread = 3
			, eval_metric = "auc"
			)
		, watchlist = list(test = xgb.data.test)
		, nrounds = 500
		, early_stopping_rounds = 40
		, print_every_n = 20
		)
    , times = 5L
)
print(xgb.bench.acc)
print(xgb.model.acc$bestScore)

#Get feature importance
xgb.feature.imp = xgb.importance(model = xgb.model.acc)

# Make predictions on test set for ROC curve
xgb.test.acc = predict(xgb.model.acc
                   , newdata = as.matrix(test[, colnames(test) != "Class"])
                   , ntreelimit = xgb.model.acc$best_ntreelimit)
auc.xgb.acc = roc(test$Class, xgb.test.acc, plot = TRUE, col = "blue")
print(auc.xgb.acc)
```

```{r}
# xgBoost with Histogram
xgb.bench.hist = microbenchmark(
	xgb.model.hist <- xgb.train(data = xgb.data.train
		, params = list(objective = "binary:logistic"
			, eta = 0.1
			, max.depth = 7
			, min_child_weight = 100
			, subsample = 1
			, colsample_bytree = 1
			, nthread = 3
			, eval_metric = "auc"
            , tree_method = "hist"
            , grow_policy = "lossguide"
			)
		, watchlist = list(test = xgb.data.test)
		, nrounds = 500
		, early_stopping_rounds = 40
		, print_every_n = 20
		)
    , times = 5L
)
print(xgb.bench.hist)
print(xgb.model.hist$bestScore)

#Get feature importance
xgb.feature.imp = xgb.importance(model = xgb.model.hist)

# Make predictions on test set for ROC curve
xgb.test.hist <- predict(
    xgb.model.hist,
    newdata = as.matrix(test[, colnames(test) != "Class"]),
    ntreelimit = xgb.model.hist$best_ntreelimit
)
auc.xgb.hist = roc(test$Class, xgb.test.hist, plot = TRUE, col = "blue")
print(auc.xgb.hist)
```

## LightGBM
```{r}
library(lightgbm, quietly=TRUE)
lgb.train = lgb.Dataset(as.matrix(train[, colnames(train) != "Class"]), label = train$Class)
lgb.test = lgb.Dataset(as.matrix(test[, colnames(test) != "Class"]), label = test$Class)

params.lgb = list(
	objective = "binary"
	, metric = "auc"
	, min_data_in_leaf = 1
	, min_sum_hessian_in_leaf = 100
	, feature_fraction = 1
	, bagging_fraction = 1
	, bagging_freq = 5
	, learning_rate = 0.1
	, num_leaves = 7
	, num_threads = 2
	)

# Get the time to train the lightGBM model
lgb.bench = microbenchmark(
	lgb.model <- lgb.train(
		params = params.lgb
		, data = lgb.train
		, valids = list(test = lgb.test)
		, nrounds = 500
		, early_stopping_rounds = 40
		, eval_freq = 20
		)
		, times = 5L
)
print(lgb.bench)
print(max(unlist(lgb.model$record_evals[["test"]][["auc"]][["eval"]])))

# get feature importance
lgb.feature.imp = lgb.importance(lgb.model, percentage = TRUE)

# make test predictions
lgb.test = predict(lgb.model, newdata = as.matrix(test[, colnames(test) != "Class"]), num_iteration = lgb.model$best_iter)
auc.lgb = roc(test$Class, lgb.test, plot = TRUE, col = "green")
print(auc.lgb)
```

## Results
### Speed
The following shows the estimated GBM benchmark (see above for actual) and the microbenchmark results for the xgboost and lightgbm models.
```{r}
print("GBM = ~243s")
print(xgb.bench.speed)
print(xgb.bench.hist)
print(lgb.bench)
```

## Accuracy
The following are the AUC results for the test set.

### GBM
```{r}
print(auc.gbm)
```
### XGBoost
```{r}
print(auc.xgb.acc)
print(auc.xgb.hist)
```
### LightGBM
```{r}
print(auc.lgb)
```
## Feature Importance
The top features selected by all three models were very similar. The top 4 features were the same expect for LightGBM selecting v4 as an important feature.

### GBM
```{r}
print(gbm.feature.imp)
```
### XGBoost
```{r}
print(xgb.feature.imp)
```
### LightGBM
```{r}
print(lgb.feature.imp)
```
## Conclusion
LightGBM is the fastest and most accurate methods.

### Advantages and disadvantages of each methods
GBM
Disadvantages:
- No early exit
- Slower training
- Less accurate

xgboost
Advantages:
- Proven success (on kaggle)
- Now with Histogram Binning

Disadvantages:
- Traditionally slower than lightGBM, but tree_method = 'hist' is a big improvement.

LightGBM:
Adv: 
- Fast training efficiency
- Low memory usage
- Better accuracy
- Parallel learning supported
- Deal with large scale data
- Corporate 

## References
- [1] https://www.kaggle.com/code/nschneider/gbm-vs-xgboost-vs-lightgbm
